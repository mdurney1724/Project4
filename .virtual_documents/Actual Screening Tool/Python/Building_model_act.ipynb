


# Import our dependencies
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import pandas as pd
from pathlib import Path
from sqlalchemy import create_engine
import sqlite3
import os
import tensorflow as tf

# Import and read the diabetes_data.csv.
#diabetes_df = pd.read_csv("Resources/diabetes_data.csv")

#Define the paths
resources_folder = os.path.join(os.getcwd(), 'resources')
csv_file_path = os.path.join(resources_folder, 'diabetes_data.csv')
database_path = os.path.join(os.getcwd(), 'my_database2.db')

#Load the CSV file into a pandas DataFrame
df = pd.read_csv(csv_file_path)

#Connect to the SQLite database (or create it)
connection = sqlite3.connect(database_path)

#Save the DataFrame to the SQLite database
df.to_sql('diabetes_data', connection, if_exists='replace', index=False)

#Commit and close the connection
connection.commit()
connection.close()

#Verify the data by querying the database
connection = sqlite3.connect(database_path)
diabetes_df = pd.read_sql('SELECT * FROM diabetes_data', connection)
diabetes_BMI = pd.read_sql('SELECT BMI FROM diabetes_data', connection)
diabetes_df.head()
#diabetes_BMI.head(4)

# Drop the column smoking_history 
diabetes_df.drop('smoking_history', axis=1, inplace=True)

# Remove all rows where gender is 'Other'
diabetes_df = diabetes_df[diabetes_df['gender'] != 'Other']

# Reset the index after removing rows
diabetes_df.reset_index(drop=True, inplace=True)
diabetes_df.head()


# Determine the number of unique values in each column.
diabetes_df.nunique()


# Convert gender values column to numerical values
diabetes_df = diabetes_df.replace({'gender': {'Female': 0, 'Male': 1}})
diabetes_df.head()


# Split our preprocessed data into our features and target arrays
y = diabetes_df['diabetes'].values
X = diabetes_df.drop('diabetes', axis=1).values

# Split the preprocessed data into a training and testing dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)





# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.
number_input_features = len(X_train[0])
hidden_nodes_layer1 = 8
hidden_nodes_layer2 = 5

nn = tf.keras.models.Sequential()

# First hidden layer
nn.add(
    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation="relu")
)

# Second hidden layer
nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation="relu"))

# Output layer
nn.add(tf.keras.layers.Dense(units=1, activation="sigmoid"))

# Check the structure of the model
nn.summary()


# Compile the model
nn.compile(loss="binary_crossentropy", optimizer="adam", metrics=["accuracy"])




# Train the model
fit_model = nn.fit(X_train,y_train,epochs=100)


# Evaluate the model using the test data
model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)
print(f"Loss: {model_loss}, Accuracy: {model_accuracy}")


# Export our model to HDF5 file
nn.save('diabetes_prediction_model.h5')



