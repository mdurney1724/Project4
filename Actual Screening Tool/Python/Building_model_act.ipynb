{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uR68591Ul8m4"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "bl4ygIROl8m7",
    "outputId": "73319919-b65a-496f-c3cb-119eec147b46"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease    bmi  HbA1c_level  \\\n",
       "0  Female  80.0             0              1  25.19          6.6   \n",
       "1  Female  54.0             0              0  27.32          6.6   \n",
       "2    Male  28.0             0              0  27.32          5.7   \n",
       "3  Female  36.0             0              0  23.45          5.0   \n",
       "4    Male  76.0             1              1  20.14          4.8   \n",
       "\n",
       "   blood_glucose_level  diabetes  \n",
       "0                  140         0  \n",
       "1                   80         0  \n",
       "2                  158         0  \n",
       "3                  155         0  \n",
       "4                  155         0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine\n",
    "import sqlite3\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import and read the diabetes_data.csv.\n",
    "#diabetes_df = pd.read_csv(\"Resources/diabetes_data.csv\")\n",
    "\n",
    "#Define the paths\n",
    "resources_folder = os.path.join(os.getcwd(), 'resources')\n",
    "csv_file_path = os.path.join(resources_folder, 'diabetes_data.csv')\n",
    "database_path = os.path.join(os.getcwd(), 'my_database2.db')\n",
    "\n",
    "#Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "#Connect to the SQLite database (or create it)\n",
    "connection = sqlite3.connect(database_path)\n",
    "\n",
    "#Save the DataFrame to the SQLite database\n",
    "df.to_sql('diabetes_data', connection, if_exists='replace', index=False)\n",
    "\n",
    "#Commit and close the connection\n",
    "connection.commit()\n",
    "connection.close()\n",
    "\n",
    "#Verify the data by querying the database\n",
    "connection = sqlite3.connect(database_path)\n",
    "diabetes_df = pd.read_sql('SELECT * FROM diabetes_data', connection)\n",
    "diabetes_BMI = pd.read_sql('SELECT BMI FROM diabetes_data', connection)\n",
    "diabetes_df.head()\n",
    "#diabetes_BMI.head(4)\n",
    "\n",
    "# Drop the column smoking_history \n",
    "diabetes_df.drop('smoking_history', axis=1, inplace=True)\n",
    "\n",
    "# Remove all rows where gender is 'Other'\n",
    "diabetes_df = diabetes_df[diabetes_df['gender'] != 'Other']\n",
    "\n",
    "# Reset the index after removing rows\n",
    "diabetes_df.reset_index(drop=True, inplace=True)\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "id": "17KWd7Xpl8m-",
    "outputId": "5bb63ec7-f267-4d44-af57-f2b964b9894f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                    2\n",
       "age                     102\n",
       "hypertension              2\n",
       "heart_disease             2\n",
       "bmi                    4247\n",
       "HbA1c_level              18\n",
       "blood_glucose_level      18\n",
       "diabetes                  2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "diabetes_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease    bmi  HbA1c_level  \\\n",
       "0       0  80.0             0              1  25.19          6.6   \n",
       "1       0  54.0             0              0  27.32          6.6   \n",
       "2       1  28.0             0              0  27.32          5.7   \n",
       "3       0  36.0             0              0  23.45          5.0   \n",
       "4       1  76.0             1              1  20.14          4.8   \n",
       "\n",
       "   blood_glucose_level  diabetes  \n",
       "0                  140         0  \n",
       "1                   80         0  \n",
       "2                  158         0  \n",
       "3                  155         0  \n",
       "4                  155         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert gender values column to numerical values\n",
    "diabetes_df = diabetes_df.replace({'gender': {'Female': 0, 'Male': 1}})\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DXB1f2qzl8nC"
   },
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = diabetes_df['diabetes'].values\n",
    "X = diabetes_df.drop('diabetes', axis=1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSV4DxjQl8nD"
   },
   "source": [
    "## Compile, Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "_NI-CpRXl8nE",
    "outputId": "2cb41bf7-8202-42a9-bc6a-41a1c35104ba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victor Doan\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │              \u001b[38;5;34m64\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m45\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m6\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">115</span> (460.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m115\u001b[0m (460.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">115</span> (460.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m115\u001b[0m (460.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 8\n",
    "hidden_nodes_layer2 = 5\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OCROrvzpl8nE"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xzba2tL-l8nE",
    "outputId": "7f80a6e0-982b-4e38-fbec-4077be021b48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 651us/step - accuracy: 0.8988 - loss: 0.3952\n",
      "Epoch 2/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 646us/step - accuracy: 0.9263 - loss: 0.2388\n",
      "Epoch 3/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 683us/step - accuracy: 0.9313 - loss: 0.2051\n",
      "Epoch 4/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 634us/step - accuracy: 0.9369 - loss: 0.1826\n",
      "Epoch 5/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 637us/step - accuracy: 0.9416 - loss: 0.1660\n",
      "Epoch 6/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 682us/step - accuracy: 0.9472 - loss: 0.1515\n",
      "Epoch 7/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 716us/step - accuracy: 0.9511 - loss: 0.1426\n",
      "Epoch 8/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 725us/step - accuracy: 0.9506 - loss: 0.1400\n",
      "Epoch 9/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 712us/step - accuracy: 0.9527 - loss: 0.1343\n",
      "Epoch 10/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 709us/step - accuracy: 0.9543 - loss: 0.1299\n",
      "Epoch 11/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 667us/step - accuracy: 0.9531 - loss: 0.1289\n",
      "Epoch 12/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 753us/step - accuracy: 0.9552 - loss: 0.1248\n",
      "Epoch 13/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 692us/step - accuracy: 0.9538 - loss: 0.1283\n",
      "Epoch 14/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 670us/step - accuracy: 0.9545 - loss: 0.1248\n",
      "Epoch 15/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 680us/step - accuracy: 0.9551 - loss: 0.1234\n",
      "Epoch 16/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 677us/step - accuracy: 0.9569 - loss: 0.1202\n",
      "Epoch 17/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 684us/step - accuracy: 0.9557 - loss: 0.1223\n",
      "Epoch 18/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 774us/step - accuracy: 0.9551 - loss: 0.1215\n",
      "Epoch 19/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 686us/step - accuracy: 0.9552 - loss: 0.1225\n",
      "Epoch 20/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 709us/step - accuracy: 0.9554 - loss: 0.1240\n",
      "Epoch 21/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 734us/step - accuracy: 0.9555 - loss: 0.1220\n",
      "Epoch 22/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 709us/step - accuracy: 0.9569 - loss: 0.1195\n",
      "Epoch 23/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 724us/step - accuracy: 0.9565 - loss: 0.1194\n",
      "Epoch 24/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 730us/step - accuracy: 0.9574 - loss: 0.1177\n",
      "Epoch 25/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 730us/step - accuracy: 0.9545 - loss: 0.1239\n",
      "Epoch 26/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 718us/step - accuracy: 0.9561 - loss: 0.1208\n",
      "Epoch 27/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 737us/step - accuracy: 0.9565 - loss: 0.1192\n",
      "Epoch 28/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 769us/step - accuracy: 0.9574 - loss: 0.1195\n",
      "Epoch 29/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 760us/step - accuracy: 0.9561 - loss: 0.1200\n",
      "Epoch 30/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 733us/step - accuracy: 0.9584 - loss: 0.1162\n",
      "Epoch 31/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 732us/step - accuracy: 0.9562 - loss: 0.1201\n",
      "Epoch 32/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 745us/step - accuracy: 0.9570 - loss: 0.1196\n",
      "Epoch 33/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 742us/step - accuracy: 0.9568 - loss: 0.1185\n",
      "Epoch 34/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 737us/step - accuracy: 0.9590 - loss: 0.1162\n",
      "Epoch 35/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 724us/step - accuracy: 0.9577 - loss: 0.1187\n",
      "Epoch 36/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 714us/step - accuracy: 0.9558 - loss: 0.1204\n",
      "Epoch 37/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 702us/step - accuracy: 0.9580 - loss: 0.1162\n",
      "Epoch 38/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 711us/step - accuracy: 0.9574 - loss: 0.1169\n",
      "Epoch 39/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 812us/step - accuracy: 0.9562 - loss: 0.1184\n",
      "Epoch 40/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 762us/step - accuracy: 0.9565 - loss: 0.1183\n",
      "Epoch 41/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 845us/step - accuracy: 0.9590 - loss: 0.1160\n",
      "Epoch 42/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 834us/step - accuracy: 0.9606 - loss: 0.1132\n",
      "Epoch 43/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 714us/step - accuracy: 0.9591 - loss: 0.1146\n",
      "Epoch 44/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 715us/step - accuracy: 0.9590 - loss: 0.1148\n",
      "Epoch 45/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 724us/step - accuracy: 0.9596 - loss: 0.1147\n",
      "Epoch 46/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 706us/step - accuracy: 0.9598 - loss: 0.1136\n",
      "Epoch 47/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 730us/step - accuracy: 0.9592 - loss: 0.1168\n",
      "Epoch 48/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 778us/step - accuracy: 0.9574 - loss: 0.1173\n",
      "Epoch 49/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 747us/step - accuracy: 0.9597 - loss: 0.1166\n",
      "Epoch 50/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 748us/step - accuracy: 0.9592 - loss: 0.1144\n",
      "Epoch 51/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 736us/step - accuracy: 0.9616 - loss: 0.1120\n",
      "Epoch 52/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 730us/step - accuracy: 0.9607 - loss: 0.1121\n",
      "Epoch 53/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 773us/step - accuracy: 0.9588 - loss: 0.1139\n",
      "Epoch 54/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 858us/step - accuracy: 0.9609 - loss: 0.1118\n",
      "Epoch 55/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 798us/step - accuracy: 0.9614 - loss: 0.1107\n",
      "Epoch 56/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 809us/step - accuracy: 0.9610 - loss: 0.1133\n",
      "Epoch 57/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 722us/step - accuracy: 0.9600 - loss: 0.1129\n",
      "Epoch 58/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 726us/step - accuracy: 0.9611 - loss: 0.1125\n",
      "Epoch 59/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 689us/step - accuracy: 0.9618 - loss: 0.1097\n",
      "Epoch 60/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 698us/step - accuracy: 0.9616 - loss: 0.1100\n",
      "Epoch 61/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 687us/step - accuracy: 0.9606 - loss: 0.1127\n",
      "Epoch 62/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 678us/step - accuracy: 0.9617 - loss: 0.1115\n",
      "Epoch 63/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 666us/step - accuracy: 0.9623 - loss: 0.1103\n",
      "Epoch 64/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 684us/step - accuracy: 0.9630 - loss: 0.1093\n",
      "Epoch 65/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 688us/step - accuracy: 0.9624 - loss: 0.1086\n",
      "Epoch 66/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 707us/step - accuracy: 0.9616 - loss: 0.1112\n",
      "Epoch 67/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 786us/step - accuracy: 0.9614 - loss: 0.1105\n",
      "Epoch 68/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 756us/step - accuracy: 0.9609 - loss: 0.1118\n",
      "Epoch 69/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 756us/step - accuracy: 0.9618 - loss: 0.1082\n",
      "Epoch 70/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 778us/step - accuracy: 0.9618 - loss: 0.1096\n",
      "Epoch 71/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 814us/step - accuracy: 0.9617 - loss: 0.1092\n",
      "Epoch 72/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 760us/step - accuracy: 0.9640 - loss: 0.1052\n",
      "Epoch 73/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 877us/step - accuracy: 0.9621 - loss: 0.1106\n",
      "Epoch 74/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 904us/step - accuracy: 0.9628 - loss: 0.1070\n",
      "Epoch 75/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 796us/step - accuracy: 0.9626 - loss: 0.1077\n",
      "Epoch 76/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 861us/step - accuracy: 0.9642 - loss: 0.1067\n",
      "Epoch 77/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 785us/step - accuracy: 0.9634 - loss: 0.1063\n",
      "Epoch 78/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 793us/step - accuracy: 0.9633 - loss: 0.1072\n",
      "Epoch 79/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 794us/step - accuracy: 0.9640 - loss: 0.1050\n",
      "Epoch 80/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 732us/step - accuracy: 0.9631 - loss: 0.1076\n",
      "Epoch 81/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 718us/step - accuracy: 0.9647 - loss: 0.1022\n",
      "Epoch 82/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 740us/step - accuracy: 0.9632 - loss: 0.1070\n",
      "Epoch 83/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 693us/step - accuracy: 0.9630 - loss: 0.1081\n",
      "Epoch 84/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 719us/step - accuracy: 0.9644 - loss: 0.1053\n",
      "Epoch 85/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 724us/step - accuracy: 0.9631 - loss: 0.1061\n",
      "Epoch 86/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 714us/step - accuracy: 0.9631 - loss: 0.1061\n",
      "Epoch 87/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 817us/step - accuracy: 0.9620 - loss: 0.1071\n",
      "Epoch 88/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 987us/step - accuracy: 0.9638 - loss: 0.1054\n",
      "Epoch 89/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 873us/step - accuracy: 0.9648 - loss: 0.1044\n",
      "Epoch 90/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 922us/step - accuracy: 0.9639 - loss: 0.1076\n",
      "Epoch 91/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 861us/step - accuracy: 0.9649 - loss: 0.1046\n",
      "Epoch 92/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 927us/step - accuracy: 0.9643 - loss: 0.1045\n",
      "Epoch 93/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 849us/step - accuracy: 0.9636 - loss: 0.1042\n",
      "Epoch 94/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 920us/step - accuracy: 0.9644 - loss: 0.1049\n",
      "Epoch 95/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 853us/step - accuracy: 0.9644 - loss: 0.1046\n",
      "Epoch 96/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 779us/step - accuracy: 0.9654 - loss: 0.1023\n",
      "Epoch 97/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 790us/step - accuracy: 0.9633 - loss: 0.1054\n",
      "Epoch 98/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 799us/step - accuracy: 0.9633 - loss: 0.1067\n",
      "Epoch 99/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 834us/step - accuracy: 0.9640 - loss: 0.1057\n",
      "Epoch 100/100\n",
      "\u001b[1m2344/2344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 790us/step - accuracy: 0.9638 - loss: 0.1057\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q0uJBPIsl8nF",
    "outputId": "d409eb4b-f944-4fb2-bca1-ac3782f2bbb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 1s - 688us/step - accuracy: 0.9638 - loss: 0.1064\n",
      "Loss: 0.1063760444521904, Accuracy: 0.9637942314147949\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-E2GvibNl8nF",
    "outputId": "be300d6f-ff57-49c6-83b7-b8acbcffca64"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save('diabetes_prediction_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
